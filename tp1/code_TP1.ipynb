{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KuGhQdj-SWS6"
   },
   "source": [
    "**Partie I**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "cxWIyjiNSWxl",
    "outputId": "58af21e5-7a46-438e-d6ce-172c7a77d126"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr(Pluie)=0.2\n",
      "\n",
      "Pr(Arroseur)=0.1\n",
      "\n",
      "Pr(Watson|Pluie)=1.0\n",
      "\n",
      "Pr(Holmes|Pluie,arroseur)=1.0\n",
      "\n",
      "---\n",
      "A: P(H=1) = 0.272\n",
      "\n",
      "B: P(H=1|W=1) = 0.5955555555555556\n",
      "\n",
      "C: P(H=1|W=0) = 0.16\n",
      "\n",
      "D: P(H=1|P=0,W=1) = 0.09000000000000001\n",
      "\n",
      "E: P(W=1|H=1) = 0.7882352941176471\n",
      "\n",
      "F: P(W=1|H=1,A=1) = 0.3739130434782609\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# les arrays sont batis avec les dimensions suivantes:\n",
    "# pluie, arroseur, watson, holmes\n",
    "# et chaque dimension: faux, vrai\n",
    "\n",
    "prob_pluie = np.array([0.8, 0.2]).reshape(2, 1, 1, 1)\n",
    "print (\"Pr(Pluie)={}\\n\".format(np.squeeze(prob_pluie[1,:,:,:])))\n",
    "prob_arroseur = np.array([0.9, 0.1]).reshape(1, 2, 1, 1)\n",
    "print (\"Pr(Arroseur)={}\\n\".format(np.squeeze(prob_arroseur[:,1,:,:])))\n",
    "watson = np.array([[0.8, 0.2], [0, 1]]).reshape(2, 1, 2, 1)\n",
    "print (\"Pr(Watson|Pluie)={}\\n\".format(np.squeeze(watson[1,:,1,:])))\n",
    "holmes = np.array([[1,0], [0.1,0.9], [0,1], [0,1]]).reshape(2,2,1,2)\n",
    "print (\"Pr(Holmes|Pluie,arroseur)={}\\n\".format(np.squeeze(holmes[1,1,:,1])))\n",
    "print(\"---\")\n",
    "\n",
    "prob_h = (holmes * prob_pluie * prob_arroseur * watson)[:,:,:,1].sum()\n",
    "prob_w = (holmes * prob_pluie * prob_arroseur * watson)[:,:,1,:].sum()\n",
    "\n",
    "print(\"A: P(H=1) =\",prob_h)\n",
    "\n",
    "print(\"\\nB: P(H=1|W=1) =\", (holmes * prob_pluie * prob_arroseur * watson)[:,:,1,1].sum()/prob_w)\n",
    "\n",
    "print(\"\\nC: P(H=1|W=0) =\", (holmes * prob_pluie * prob_arroseur * watson)[:,:,0,1].sum()/prob_w)\n",
    "\n",
    "print(\"\\nD: P(H=1|P=0,W=1) =\", (holmes * prob_pluie * prob_arroseur * watson)[0,:,1,1].sum()/(holmes * prob_pluie * prob_arroseur * watson)[0,:,1,:].sum())\n",
    "\n",
    "print(\"\\nE: P(W=1|H=1) =\", (holmes * prob_pluie * prob_arroseur * watson)[:,:,1,1].sum()/(holmes * prob_pluie * prob_arroseur * watson)[:,:,:,1].sum())\n",
    "\n",
    "print(\"\\nF: P(W=1|H=1,A=1) =\", (holmes * prob_pluie * prob_arroseur * watson)[:,1,1,1].sum()/(holmes * prob_pluie * prob_arroseur * watson)[:,1,:,1].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xntVFIeVSRO5"
   },
   "source": [
    "**Partie II**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kuksdusZSObi"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-ab72f59fec26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# TODO\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0maccuracies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# compute the accuracy on the validation set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbest_accuracy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m         \u001b[1;32mpass\u001b[0m  \u001b[1;31m# select the best parameters based on the validation accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '>' not supported between instances of 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "X = digits.data\n",
    "\n",
    "y = digits.target\n",
    "y_one_hot = np.zeros((y.shape[0], len(np.unique(y))))\n",
    "y_one_hot[np.arange(y.shape[0]), y] = 1  # one hot target or shape NxK\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.3, random_state=42)\n",
    "\n",
    "X_test, X_validation, y_test, y_validation = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "W = np.random.normal(0, 0.01, (len(np.unique(y)), X.shape[1]))  # weights of shape KxL\n",
    "\n",
    "best_W = None\n",
    "best_accuracy = 0\n",
    "lr = 0.001\n",
    "nb_epochs = 50\n",
    "minibatch_size = len(y) // 20\n",
    "\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "def softmax(x):\n",
    "    # assurez vous que la fonction est numeriquement stable\n",
    "    # e.g. softmax(np.array([1000, 10000, 100000], ndim=2))\n",
    "    pass\n",
    "\n",
    "def get_accuracy(X, y, W):\n",
    "    pass\n",
    "\n",
    "def get_grads(y, y_pred, X):\n",
    "    pass\n",
    "\n",
    "def get_loss(y, y_pred):\n",
    "    pass\n",
    "    \n",
    "for epoch in range(nb_epochs):\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    for i in range(0, X_train.shape[0], minibatch_size):\n",
    "        pass # TODO\n",
    "    losses.append(loss)  # compute the loss on the train set\n",
    "    accuracy = None  # TODO\n",
    "    accuracies.append(accuracy) # compute the accuracy on the validation set\n",
    "    if accuracy > best_accuracy:\n",
    "        pass  # select the best parameters based on the validation accuracy \n",
    "    \n",
    "accuracy_on_unseen_data = get_accuracy(X_test, y_test, best_W)\n",
    "print(accuracy_on_unseen_data)  # 0.897506925208\n",
    "\n",
    "plt.plot(losses)\n",
    "\n",
    "plt.imshow(best_W[4, :].reshape(8,8))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "code_TP1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
