{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KuGhQdj-SWS6"
   },
   "source": [
    "**Partie I**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "cxWIyjiNSWxl",
    "outputId": "58af21e5-7a46-438e-d6ce-172c7a77d126"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr(Pluie)=0.2\n",
      "\n",
      "Pr(Arroseur)=0.1\n",
      "\n",
      "Pr(Watson|Pluie)=1.0\n",
      "\n",
      "Pr(Holmes|Pluie,arroseur)=1.0\n",
      "\n",
      "---\n",
      "0.17120000000000005\n",
      "A: P(H=1) = 0.272\n",
      "\n",
      "Pr(Watson) = 0.36000000000000004\n",
      "0.36000000000000004\n",
      "B: P(H=1|W=1) = 0.5955555555555556\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# les arrays sont batis avec les dimensions suivantes:\n",
    "# pluie, arroseur, watson, holmes\n",
    "# et chaque dimension: faux, vrai\n",
    "\n",
    "prob_pluie = np.array([0.8, 0.2]).reshape(2, 1, 1, 1)\n",
    "print (\"Pr(Pluie)={}\\n\".format(np.squeeze(prob_pluie[1,:,:,:])))\n",
    "prob_arroseur = np.array([0.9, 0.1]).reshape(1, 2, 1, 1)\n",
    "print (\"Pr(Arroseur)={}\\n\".format(np.squeeze(prob_arroseur[:,1,:,:])))\n",
    "watson = np.array([[0.8, 0.2], [0, 1]]).reshape(2, 1, 2, 1)\n",
    "print (\"Pr(Watson|Pluie)={}\\n\".format(np.squeeze(watson[1,:,1,:])))\n",
    "holmes = np.array([[1,0], [0.1,0.9], [0,1], [0,1]]).reshape(2,2,1,2)\n",
    "print (\"Pr(Holmes|Pluie,arroseur)={}\\n\".format(np.squeeze(holmes[1,1,:,1])))\n",
    "print(\"---\")\n",
    "#print(watson[0,:,1,:])  # prob watson mouille - pluie\n",
    "#print((watson * prob_pluie).sum(0).squeeze()[1])  # prob gazon watson mouille\n",
    "#holmes[0,1,0,1]  # prob gazon holmes mouille si arroseur - pluie\n",
    "\n",
    "\n",
    "prob_h = (holmes * prob_pluie * prob_arroseur)[:,:,:,1].sum()\n",
    "print(prob_h)\n",
    "print(\"A: P(H=1) =\",(holmes * prob_pluie * prob_arroseur).sum(0).sum(0).squeeze()[1])\n",
    "print()\n",
    "\n",
    "#print(\"\\nB\")\n",
    "print(\"Pr(Watson) =\", (watson * prob_pluie).sum(0).squeeze()[1])\n",
    "#print(np.squeeze(watson[1,:,1,:]*prob_pluie[1,:,:,:] + watson[0,:,1,:] * prob_pluie[0,:,:,:]))\n",
    "prob_w = (watson * prob_pluie)[:,:,1,:].sum()\n",
    "print(prob_w)\n",
    "print(\"B: P(H=1|W=1) =\", (holmes * prob_arroseur * prob_pluie * watson)[:,:,1,1].sum()/prob_w)\n",
    "#print((prob_pluie))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xntVFIeVSRO5"
   },
   "source": [
    "**Partie II**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kuksdusZSObi"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "X = digits.data\n",
    "\n",
    "y = digits.target\n",
    "y_one_hot = np.zeros((y.shape[0], len(np.unique(y))))\n",
    "y_one_hot[np.arange(y.shape[0]), y] = 1  # one hot target or shape NxK\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.3, random_state=42)\n",
    "\n",
    "X_test, X_validation, y_test, y_validation = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "W = np.random.normal(0, 0.01, (len(np.unique(y)), X.shape[1]))  # weights of shape KxL\n",
    "\n",
    "best_W = None\n",
    "best_accuracy = 0\n",
    "lr = 0.001\n",
    "nb_epochs = 50\n",
    "minibatch_size = len(y) // 20\n",
    "\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "def softmax(x):\n",
    "    # assurez vous que la fonction est numeriquement stable\n",
    "    # e.g. softmax(np.array([1000, 10000, 100000], ndim=2))\n",
    "    pass\n",
    "\n",
    "def get_accuracy(X, y, W):\n",
    "    pass\n",
    "\n",
    "def get_grads(y, y_pred, X):\n",
    "    pass\n",
    "\n",
    "def get_loss(y, y_pred):\n",
    "    pass\n",
    "    \n",
    "for epoch in range(nb_epochs):\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    for i in range(0, X_train.shape[0], minibatch_size):\n",
    "        pass # TODO\n",
    "    losses.append(loss)  # compute the loss on the train set\n",
    "    accuracy = None  # TODO\n",
    "    accuracies.append(accuracy) # compute the accuracy on the validation set\n",
    "    if accuracy > best_accuracy:\n",
    "        pass  # select the best parameters based on the validation accuracy \n",
    "    \n",
    "accuracy_on_unseen_data = get_accuracy(X_test, y_test, best_W)\n",
    "print(accuracy_on_unseen_data)  # 0.897506925208\n",
    "\n",
    "plt.plot(losses)\n",
    "\n",
    "plt.imshow(best_W[4, :].reshape(8,8))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "code_TP1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
