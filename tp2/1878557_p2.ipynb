{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for reading and displaying images\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# for creating validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "import torch.nn\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "C:\\w\\1\\s\\tmp_conda_3.7_100118\\conda\\conda-bld\\pytorch_1579082551706\\work\\aten\\src\\ATen/native/IndexingUtils.h:20: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "train_data = datasets.FashionMNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "\n",
    "valid_data = datasets.FashionMNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "\n",
    "test_data = datasets.FashionMNIST('../data', train=False, download=True,\n",
    "                      transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "\n",
    "train_idx = np.random.choice(train_data.train_data.shape[0], 54000, replace=False)\n",
    "train_data.data = train_data.data[train_idx, :]\n",
    "train_data.targets = train_data.targets[torch.from_numpy(train_idx).type(torch.LongTensor)]\n",
    "\n",
    "mask = np.ones(60000)\n",
    "mask[train_idx] = 0\n",
    "\n",
    "valid_data.data = valid_data.data[torch.from_numpy(np.argwhere(mask)), :].squeeze()\n",
    "valid_data.targets = valid_data.targets[torch.from_numpy(mask).type(torch.ByteTensor)]\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data,\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data,\n",
    "    batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "outputs": [],
   "source": [
    "class CnnNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.cnn_layers = Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "            Conv2d(1, 4, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(4),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Defining another 2D convolution layer\n",
    "            Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(4),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.linear_layers = Sequential(\n",
    "            Linear(4 * 7 * 7, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear_layers(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "outputs": [],
   "source": [
    "class FcNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear_layers = Sequential(\n",
    "            Linear(28*28, 600),\n",
    "            ReLU(inplace=True),\n",
    "            Linear(600, 400),\n",
    "            ReLU(inplace=True),\n",
    "            Linear(400, 200),\n",
    "            ReLU(inplace=True),\n",
    "            Linear(200, 100),\n",
    "            ReLU(inplace=True),\n",
    "            Linear(100, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, image):\n",
    "        batch_size = image.size()[0]\n",
    "        x = image.view(batch_size, -1)\n",
    "        x = self.linear_layers(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "outputs": [],
   "source": [
    "lossFct = nn.NLLLoss(reduction='sum')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "outputs": [],
   "source": [
    "def train(model, optimizer):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = lossFct(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "def valid(model):\n",
    "    valid_loss = 0\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data, target in valid_loader:\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        valid_loss += F.nll_loss(output, target, size_average=False).data \n",
    "        pred = output.data.max(1, keepdim=True)[1] \n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "    return valid_loss, 1. * correct / len(valid_loader.dataset)\n",
    "\n",
    "\n",
    "def test(model, name):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, size_average=False).data\n",
    "        pred = output.data.max(1, keepdim=True)[1] \n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "    print('\\n' + name + \" test\" + ' set: Total loss: {:.4f}, Accuracy: {:.0f}%\\n'.format(\n",
    "        test_loss, 100. * correct / len(test_loader.dataset)))\n",
    "    return test_loss, 1. * correct / len(test_loader.dataset)\n",
    "        \n",
    "\n",
    "def fit(model, optimizer, name):\n",
    "    lossTot = 0\n",
    "    for i in range(5):\n",
    "        train(model, optimizer)\n",
    "        lossTot += valid(model)[0]\n",
    "    test(model, name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "\nCnn test set: Total loss: 3748.9939, Accuracy: 87%\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "cnn = CnnNet()\n",
    "cnnOptimizer = Adam(cnn.parameters(), lr=0.001)\n",
    "fit(cnn, cnnOptimizer, \"Cnn\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "\nFully connected test set: Total loss: 3443.1460, Accuracy: 87%\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "fc = FcNetwork()\n",
    "fcOptimizer = SGD(fc.parameters(), lr=0.001)\n",
    "fit(fc, fcOptimizer, \"Fully connected\")\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}