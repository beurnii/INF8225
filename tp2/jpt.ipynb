{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "L = 2\n",
    "K = 10\n",
    "\n",
    "\n",
    "X_train = np.reshape(train_images, (train_images.shape[0], 784))\n",
    "X_test = np.reshape(test_images, (test_images.shape[0], 784))\n",
    "\n",
    "Y_train = np.zeros((train_labels.shape[0], len(np.unique(train_labels))))\n",
    "Y_train[np.arange(Y_train.shape[0]), train_labels] = 1\n",
    "\n",
    "Y_test = np.zeros((test_labels.shape[0], len(np.unique(test_labels))))\n",
    "Y_test[np.arange(Y_test.shape[0]), test_labels] = 1\n",
    "\n",
    "\n",
    "lr = 0.001\n",
    "nb_epochs = 50\n",
    "W = []\n",
    "losses_test = []\n",
    "\n",
    "W.append(np.random.normal(0, 0.01, (784, 300)))\n",
    "for i in range(L-1):\n",
    "    W.append(np.random.normal(0, 0.01, (301, 300)))\n",
    "W.append(np.random.normal(0, 0.01, (301, K)))\n",
    "\n",
    "\n",
    "def softmax(z):\n",
    "    exp = np.exp(z - z.max(1)[:, np.newaxis])\n",
    "    return np.array(exp / exp.sum(1)[:, np.newaxis])\n",
    "\n",
    "\n",
    "def softMaxInverse(z):\n",
    "    sm = softmax(z)\n",
    "    return sm * (1-sm)\n",
    "\n",
    "\n",
    "def ReLU(z):\n",
    "    return np.maximum(z, 0)\n",
    "\n",
    "\n",
    "def ReLUReverse(z):\n",
    "    return (z >= 0).astype(int)\n",
    "\n",
    "\n",
    "def get_loss(y, y_pred):\n",
    "    return np.nanmean(-y * np.log(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def main():\n",
    "    minibatch_size = len(X_train) // 20\n",
    "    for epoch in range(nb_epochs):\n",
    "        print(\"Epoch----------------\", epoch)\n",
    "        for x in range(0, X_train.shape[0], minibatch_size):\n",
    "            Z = [None] * (L + 2)\n",
    "            a = [None] * (L + 2)\n",
    "            delta = [None] * (L + 2)\n",
    "\n",
    "            #forward propagation\n",
    "            a[0] = X_train[x:x+minibatch_size]\n",
    "            for i in range(L):\n",
    "                Z[i + 1] = a[i] @ W[i]\n",
    "                a[i + 1] = np.append(ReLU(Z[i+1]), np.ones((Z[i+1].shape[0], 1), dtype=int), axis=1)\n",
    "\n",
    "            Z[-1] = a[L] @ W[L]\n",
    "            a[-1] = softmax(Z[-1])\n",
    "\n",
    "            #back propagation\n",
    "            delta[-1] = softMaxInverse(Z[-1]) * (Y_train[x:x+minibatch_size] - a[-1])\n",
    "            for i in range(L, 0, -1):\n",
    "                m = (delta[i+1] @ W[i].T)\n",
    "                delta[i] = ReLUReverse(Z[i]) * m[:,:-1]\n",
    "\n",
    "\n",
    "            for i in range(len(W)):\n",
    "                o = np.matmul(a[i][:,:,np.newaxis], delta[i+1][:,np.newaxis,:])\n",
    "                W[i] = W[i] + lr * np.mean(o, axis=0)\n",
    "\n",
    "        test()   "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def test():\n",
    "    Z_test = [None] * (L + 2)\n",
    "    a_test = [None] * (L + 2)\n",
    "\n",
    "    a_test[0] = X_test\n",
    "    for i in range(L):\n",
    "        Z_test[i + 1] = a_test[i] @ W[i]\n",
    "        r = ReLU(Z_test[i+1])\n",
    "        b = np.ones((Z_test[i+1].shape[0], 1), dtype=int)\n",
    "        a_test[i + 1] = np.append(r, b, axis=1)\n",
    "\n",
    "    Z_test[-1] = a_test[L] @ W[L]\n",
    "    a_test[-1] = softmax(Z_test[-1])\n",
    "\n",
    "    losses_test.append(get_loss(Y_test, a_test[-1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def guess(index):\n",
    "    Z_test = [None] * (L + 2)\n",
    "    a_test = [None] * (L + 2)\n",
    "    a_test[0] = X_test[index]\n",
    "    for i in range(L):\n",
    "        Z_test[i + 1] = a_test[i] @ W[i]\n",
    "        q = ReLU(Z_test[i+1])\n",
    "        f = np.ones((Z_test[i+1].shape[0], 1), dtype=int)\n",
    "        a_test[i + 1] = np.append(ReLU(Z_test[i+1]), 1)\n",
    "    Z_test[-1] = a_test[L] @ W[L]\n",
    "    a_test[-1] = softmax(Z_test[-1])\n",
    "    plt.hist(a_test[-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Epoch---------------- 0\n",
      "Epoch---------------- 1\n",
      "Epoch---------------- 2\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "main()\n",
    "plt.plot(losses_test)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "print(losses_test)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}