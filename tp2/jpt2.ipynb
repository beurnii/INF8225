{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "L = 2\n",
    "K = 10\n",
    "\n",
    "\n",
    "X_train = np.reshape(train_images, (train_images.shape[0], 784))\n",
    "X_test = np.reshape(test_images, (test_images.shape[0], 784))\n",
    "\n",
    "Y_train = np.zeros((train_labels.shape[0], len(np.unique(train_labels))))\n",
    "Y_train[np.arange(Y_train.shape[0]), train_labels] = 1\n",
    "\n",
    "Y_test = np.zeros((test_labels.shape[0], len(np.unique(test_labels))))\n",
    "Y_test[np.arange(Y_test.shape[0]), test_labels] = 1\n",
    "\n",
    "\n",
    "lr = 0.001\n",
    "nb_epochs = 50\n",
    "W = []\n",
    "losses_test = []\n",
    "\n",
    "W.append(np.random.normal(0, 0.01, (784, 300)))\n",
    "for i in range(L-1):\n",
    "    W.append(np.random.normal(0, 0.01, (301, 300)))\n",
    "W.append(np.random.normal(0, 0.01, (301, K)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "def softmax(z):\n",
    "    exp = np.exp(z - z.max(0))\n",
    "    return np.array(exp / exp.sum(0)[np.newaxis,:])\n",
    "\n",
    "\n",
    "def softMaxInverse(z):\n",
    "    sm = softmax(z)\n",
    "    return sm * (1-sm)\n",
    "\n",
    "\n",
    "def ReLU(z):\n",
    "    return np.maximum(z, 0)\n",
    "\n",
    "\n",
    "def ReLUReverse(z):\n",
    "    return (z >= 0).astype(int)\n",
    "\n",
    "\n",
    "def get_loss(y, y_pred):\n",
    "    return -np.sum(y * np.log(y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def main():\n",
    "    minibatch_size = len(X_train) // 200\n",
    "    for epoch in range(nb_epochs):\n",
    "        permutaion = list(np.random.permutation(X_train.shape[0]))\n",
    "        X_shuffle = X_train[permutaion]\n",
    "        Y_shuffle = Y_train[permutaion]\n",
    "        print(\"Epoch----------------\", epoch)\n",
    "        for x in range(0, X_shuffle.shape[0], minibatch_size):\n",
    "            Z = [None] * (L + 2)\n",
    "            a = [None] * (L + 2)\n",
    "            delta = [None] * (L + 2)\n",
    "\n",
    "            #forward propagation\n",
    "            a[0] = X_train[x:x+minibatch_size].T\n",
    "            for i in range(L):\n",
    "                Z[i + 1] = W[i].T @ a[i]\n",
    "                a[i + 1] = np.append(ReLU(Z[i+1]), np.ones((1, Z[i+1].shape[1]), dtype=int), axis=0)\n",
    "\n",
    "            Z[-1] = W[L].T @ a[L] \n",
    "            a[-1] = softmax(Z[-1])\n",
    "\n",
    "            #back propagation\n",
    "            delta[-1] = (Y_shuffle[x:x+minibatch_size].T - a[-1]) * softMaxInverse(Z[-1])\n",
    "            for i in range(L, 0, -1):\n",
    "                delta[i] = ( W[i] @ delta[i+1])[:-1,:] * ReLUReverse(Z[i])\n",
    "\n",
    "            for i in range(len(W)):\n",
    "                g = a[i] @ delta[i+1].T / minibatch_size\n",
    "                W[i] = W[i] + lr * g\n",
    "\n",
    "\n",
    "        test()   "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test():\n",
    "    Z_test = [None] * (L + 2)\n",
    "    a_test = [None] * (L + 2)\n",
    "\n",
    "    a_test[0] = X_test\n",
    "    for i in range(L):\n",
    "        Z_test[i + 1] = a_test[i] @ W[i]\n",
    "        r = ReLU(Z_test[i+1])\n",
    "        b = np.ones((Z_test[i+1].shape[0], 1), dtype=int)\n",
    "        a_test[i + 1] = np.append(r, b, axis=1)\n",
    "\n",
    "    Z_test[-1] = a_test[L] @ W[L]\n",
    "    a_test[-1] = softmax(Z_test[-1])\n",
    "\n",
    "    losses_test.append(get_loss(Y_test, a_test[-1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def softmax1D(z):\n",
    "    exp = np.exp(z - z.max(0))\n",
    "    return np.array(exp / exp.sum(0))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def guess(index):\n",
    "    Z_test = [None] * (L + 2)\n",
    "    a_test = [None] * (L + 2)\n",
    "    a_test[0] = X_test[index]\n",
    "    for i in range(L):\n",
    "        Z_test[i + 1] = a_test[i] @ W[i]\n",
    "        q = ReLU(Z_test[i+1])\n",
    "        f = np.ones((Z_test[i+1].shape[0], 1), dtype=int)\n",
    "        a_test[i + 1] = np.append(ReLU(Z_test[i+1]), 1)\n",
    "    Z_test[-1] = a_test[L] @ W[L]\n",
    "    a_test[-1] = softmax1D(Z_test[-1])\n",
    "    plt.imshow(test_images[index])\n",
    "    plt.show()\n",
    "    for j, k in enumerate(a_test[-1]):\n",
    "        print(j, k)\n",
    "    print(\"Correct: \", test_labels[index], \"Choisi: \", np.argmax(a_test[-1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Epoch---------------- 0\n",
      "Epoch---------------- 1\n",
      "Epoch---------------- 2\n",
      "Epoch---------------- 3\n",
      "Epoch---------------- 4\n",
      "Epoch---------------- 5\n",
      "Epoch---------------- 6\n",
      "Epoch---------------- 7\n",
      "Epoch---------------- 8\n",
      "Epoch---------------- 9\n",
      "Epoch---------------- 10\n",
      "Epoch---------------- 11\n",
      "Epoch---------------- 12\n",
      "Epoch---------------- 13\n",
      "Epoch---------------- 14\n",
      "Epoch---------------- 15\n",
      "Epoch---------------- 16\n",
      "Epoch---------------- 17\n",
      "Epoch---------------- 18\n",
      "Epoch---------------- 19\n",
      "Epoch---------------- 20\n",
      "Epoch---------------- 21\n",
      "Epoch---------------- 22\n",
      "Epoch---------------- 23\n",
      "Epoch---------------- 24\n",
      "Epoch---------------- 25\n",
      "Epoch---------------- 26\n",
      "Epoch---------------- 27\n",
      "Epoch---------------- 28\n",
      "Epoch---------------- 29\n",
      "Epoch---------------- 30\n",
      "Epoch---------------- 31\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "losses_test.clear()\n",
    "main()\n",
    "plt.plot(losses_test)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "guess(1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}