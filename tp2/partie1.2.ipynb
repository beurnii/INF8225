{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "C:\\w\\1\\s\\tmp_conda_3.7_100118\\conda\\conda-bld\\pytorch_1579082551706\\work\\aten\\src\\ATen/native/IndexingUtils.h:20: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead.\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x23501084508>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 45
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAARkUlEQVR4nO3dfWyd5XkG8Os69rGdOHESkxCSED6bwaBagbkEyjZR0TEaqU0qrRPpVFjbNUgFCaRKK+omlWn/oIkWVWiqlo6ogVJQp5aSraxrFlWiiI7hZCEkDV1SlhDj4JAmJLaJ7WOfe3/4ZTLBz/2a803v6ydZxz6333PunPjyOT7P+zwPzQwi8tuv0OwGRKQxFHaRIBR2kSAUdpEgFHaRINobeWcd7LQudDfyLkVCGcMoJmycs9WqCjvJWwB8E0AbgH8ys/u97+9CN9bypmruUkQcz9uOZK3il/Ek2wD8A4CPA7gCwEaSV1R6eyJSX9X8zX4tgINm9oqZTQB4AsD62rQlIrVWTdhXATgy4+uB7Lp3ILmJZD/J/hLGq7g7EalGNWGf7U2Ad517a2abzazPzPqK6Kzi7kSkGtWEfQDA6hlfnw9gsLp2RKReqgn7CwDWkLyYZAeAWwFsq01bIlJrFQ+9mdkkybsA/Dumh962mNm+mnUmIjVV1Ti7mT0N4Oka9SIidaTTZUWCUNhFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFglDYRYKoastmkocADAOYAjBpZn21aEpEaq+qsGc+ambHa3A7IlJHehkvEkS1YTcAPyW5k+Sm2b6B5CaS/ST7Sxiv8u5EpFLVvoy/wcwGSZ4LYDvJl83smZnfYGabAWwGgB72WpX3JyIVquqZ3cwGs8tjAJ4EcG0tmhKR2qs47CS7SS58+3MANwPYW6vGRKS2qnkZvxzAkyTfvp3vmdlPatKViNRcxWE3s1cAfKiGvYhIHWnoTSQIhV0kCIVdJAiFXSQIhV0kiFpMhJEqsdjh1m2yVPmNW3UnLR6/43q3fmKt39vvfL4/WSv83uXuseU9L7v197VCW7pWnqrPXdblVkWk5SjsIkEo7CJBKOwiQSjsIkEo7CJBKOwiQWicvRGmpwEnWWmibndt1/sTEx94/B/d+pvl3W59x/CVbv3Sl4eStdt6/Nu+5RN/7tZt5z63zvb0j7dNTrrH5v2fsc0ZJ58L53jLO62iwnF4PbOLBKGwiwShsIsEobCLBKGwiwShsIsEobCLBKFx9kbImVPetvQct37kc5e59dEr09tq/fjGh9xjHz15nVsfGu9x6wuLY2795fLKZO0R90jg+i3/7daf+1DeOgDpsXRvDB4A2Nnp1sujo249V944fx3omV0kCIVdJAiFXSQIhV0kCIVdJAiFXSQIhV0kCI2zN8Drd3/ErX/mL7e79VOTb7j13+8+lKwNW9E99tUzvW59Tfcxt/7rt5a69Q3n7krWnhtd4x67cfELbv2737vTrV/ymfR8+bz57Lnz3as0+qdrk7UFT/nnF1S6/kHuMzvJLSSPkdw747pekttJHsgul1R07yLSMHN5Gf8dALecdd29AHaY2RoAO7KvRaSF5YbdzJ4BcOKsq9cD2Jp9vhXAhhr3JSI1VukbdMvN7CgAZJfnpr6R5CaS/ST7S0ifwy0i9VX3d+PNbLOZ9ZlZXxH+5AIRqZ9Kwz5EcgUAZJf+W7Yi0nSVhn0bgNuzz28H8FRt2hGReqHlzLUm+TiAGwEsBTAE4GsAfgTg+wAuAPAqgE+b2dlv4r1LD3ttLW+qsuU68fbLBty1utsvusA99MfPbXPrX3rNn1PeTn+d8FdG0mPd37z4n91j900k324BAOx862K3fvX8w279kuLxZG3XmP+4FVB267f1pG8bAJ4YTo8I/83O9e6xGOxyyx+45ohbv2aJX7+5Z2+y9vmffNE9ds2dzydrz9sOnLYTsy56n3tSjZltTJRaNLUiMhudLisShMIuEoTCLhKEwi4ShMIuEsT7a4przja6ValwG1wAwFh1pwGPT/n/DSem5rv1jy3bn6x96eCt7rEH9q1y6zvWf92tL2vze39ubGGytrDgL0NdMn849LFhfwnuZW2nk7XvXvewe2yB/rDfcNkfmnvxzIVufd94+nH/yNW/co/1Jzyn6ZldJAiFXSQIhV0kCIVdJAiFXSQIhV0kCIVdJIjWGmfPG0fPmY5bT6/fk14OetOmf3GPfeikP+b64Z7/desl8/+bPtadHmffNd+fRvp3n3jSrS8s+P8n3jg6ALxZTp8jMDw1zz12cdtbfr3g109MLUjWBif9BZFHy/6qSsdL/r97aXHYrXvnEKxd5P88/NuV6SnRPPhssqZndpEgFHaRIBR2kSAUdpEgFHaRIBR2kSAUdpEgWmucvYpx9PYV57n1IxsvceufvO3nbv2Czh8la+Nlf1vkKfhj1RcWT7r1T3b748kDk+m5149c+Ix77I4z/rzszSc/6NYv6zrq1rtYStZKBf/H7zfOODkAvJkzz99zTvuIW59f8Nco6M6p97b5t+8t0b00pzdrd56jnXNV9MwuEoTCLhKEwi4ShMIuEoTCLhKEwi4ShMIuEkRLjbOPr/uwW+/5Snob3D8854B7bG/bbrc+VFrk1n9x6tJkbVHxjHvs5fP8sehyzu/cv33jCrc+OJ7ufWXnKffY3vZRt14sTLr1wxPp7aIBf/31vHXhizlbVefVvfMfTuWM0efd9ljOGgODE/58+QLS55Qsa0+vdw8AHHXW2y+nH+/cZ3aSW0geI7l3xnX3kXyN5O7sY13e7YhIc83lZfx3ANwyy/UPmtlV2cfTtW1LRGotN+xm9gyAEw3oRUTqqJo36O4iuSd7mZ/8A4XkJpL9JPtLqG5PNBGpXKVh/xaASwFcBeAogOTuf2a22cz6zKyvCH8RPxGpn4rCbmZDZjZlZmUA3wZwbW3bEpFaqyjsJFfM+PJTAPamvldEWkPuODvJxwHcCGApyQEAXwNwI8mrABiAQwDumMudsVBAYUF6ve2Bm/xxV7yWnrP++oi/jvcHFh9366vmvenWr1gwmKx10R+Lnsr5nTqf/nsZn1vyX279gvb0vO+8Nevz5tqvLvrvza7MmYvvzWc/UvL3V+8qTLj1cwr+OQLzC+n7LsLff31Zm7+2wosTPW59zPw1Dry9ADZ0+/PZHz3j/LyU033nht3MNs5ytb+TvYi0HJ0uKxKEwi4ShMIuEoTCLhKEwi4SRGOnuLa1odCTHiI7/z/8aYWT89Nn4E0s8Lf/PUh/Kuae8/whqDPL00M15cXpIR4A6FrgDyF1FP2huzNnOtz65SuHkrU/WbbPPXZNxzG3frrsLzX97Mhlbn1Re3oZ7NXF37jHHpnwh+ZenPSHFQfG09NMj493u8eOTflDZ8dGc5a5HvF/HieG0lNs/2rEfw6+ePA/kzUrp38W9cwuEoTCLhKEwi4ShMIuEoTCLhKEwi4ShMIuEgStim2S36tF81fadZd/Mf0NztbDAFA4mV5i1yb9sWp2+avkWKc/lm3z0vXSEn9MdeR8/7aHV/u/c8s5C/x4uwfnrASN0dX+uQ1dQ/6047zbn+xO/3y1jfnnNjirLdddu786OHJWmkbOLt4ojqT/cZ2n/X/4VEf6cfvlvz6I0eNHZv0GPbOLBKGwiwShsIsEobCLBKGwiwShsIsEobCLBNHY+eylEnjk9WT59EfXuIdPdi5O1opv+WOTXcf9OeVtY/6Acdvx9Bh/x+H0MtMAsGSnf/7AkpI/H54L/LnXWJ6eqz+10B+kLy3wB4SdKeEAgHLRHyvvPJkekG4fy9lyebHfG3POEWkbc5ZVPpPz/z2a839Syhloz+mtcGLYP95x4IH0PP+pn1exZbOI/HZQ2EWCUNhFglDYRYJQ2EWCUNhFglDYRYJo6Hz2HvbaWt6Ubqboz/tuW7k8WSud768x/tZ5/njz5Dx/vNiYrhcmq3sM2yb849vH/HH64un0mDGn/GPLHf589fYR//yEwqi/3TScx806/NM8vMccAMrzco4vpp/LrODf9lSH/zyYe3xXzhoFzvkJ3QP+ZPpJ59yInb94CMOnBiqbz05yNcmfkdxPch/Ju7Pre0luJ3kgu8w5/UJEmmkuL+MnAXzZzH4XwHUA7iR5BYB7AewwszUAdmRfi0iLyg27mR01s13Z58MA9gNYBWA9gK3Zt20FsKFeTYpI9d7TG3QkLwJwNYDnASw3s6PA9C8EAOcmjtlEsp9kfwk5f9+JSN3MOewkFwD4AYB7zCw9K+QsZrbZzPrMrK+InJUTRaRu5hR2kkVMB/0xM/thdvUQyRVZfQUAfztQEWmq3CmuJAngYQD7zewbM0rbANwO4P7s8qlqm7GSP8wzefhIuk+nBgA5k0RzFbrTt1BY6G/faz059Q5/Kqd1+sNjHE9Pt2TZH3qz9pzf9znDX9aZ07tzfF5vzFlavH0iZx3raoaVJ/wprhge9etnxtzy1LAzxTWnb+8Rp6W3yJ7LfPYbAHwWwEskd2fXfRXTIf8+yS8AeBXAp+dwWyLSJLlhN7NnAaR+PafPkBGRlqLTZUWCUNhFglDYRYJQ2EWCUNhFgmjsUtLvY+XR9LiqVwMAvD5U427eqYk7G1fl/dr3+5We2UWCUNhFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFgsgNO8nVJH9Gcj/JfSTvzq6/j+RrJHdnH+vq366IVGoum0RMAviyme0iuRDATpLbs9qDZvZA/doTkVqZy/7sRwEczT4fJrkfwKp6NyYitfWe/mYneRGAqwE8n111F8k9JLeQXJI4ZhPJfpL9JYxX1ayIVG7OYSe5AMAPANxjZqcBfAvApQCuwvQz/9dnO87MNptZn5n1FdFZg5ZFpBJzCjvJIqaD/piZ/RAAzGzIzKbMrAzg2wCurV+bIlKtubwbTwAPA9hvZt+Ycf2KGd/2KQB7a9+eiNTKXN6NvwHAZwG8RHJ3dt1XAWwkeRWmd949BOCOunQoIjUxl3fjnwXAWUpP174dEakXnUEnEoTCLhKEwi4ShMIuEoTCLhKEwi4ShMIuEoTCLhKEwi4ShMIuEoTCLhKEwi4ShMIuEoTCLhIEzaxxd0a+AeDwjKuWAjjesAbem1btrVX7AtRbpWrZ24Vmtmy2QkPD/q47J/vNrK9pDThatbdW7QtQb5VqVG96GS8ShMIuEkSzw765yffvadXeWrUvQL1VqiG9NfVvdhFpnGY/s4tIgyjsIkE0JewkbyH5K5IHSd7bjB5SSB4i+VK2DXV/k3vZQvIYyb0zrusluZ3kgexy1j32mtRbS2zj7Wwz3tTHrtnbnzf8b3aSbQD+B8AfAxgA8AKAjWb2y4Y2kkDyEIA+M2v6CRgk/wjACIBHzOyD2XV/D+CEmd2f/aJcYmZfaZHe7gMw0uxtvLPdilbM3GYcwAYAf4EmPnZOX3+GBjxuzXhmvxbAQTN7xcwmADwBYH0T+mh5ZvYMgBNnXb0ewNbs862Y/mFpuERvLcHMjprZruzzYQBvbzPe1MfO6ashmhH2VQCOzPh6AK2137sB+CnJnSQ3NbuZWSw3s6PA9A8PgHOb3M/ZcrfxbqSzthlvmceuku3Pq9WMsM+2lVQrjf/dYGbXAPg4gDuzl6syN3PaxrtRZtlmvCVUuv15tZoR9gEAq2d8fT6AwSb0MSszG8wujwF4Eq23FfXQ2zvoZpfHmtzP/2ulbbxn22YcLfDYNXP782aE/QUAa0heTLIDwK0AtjWhj3ch2Z29cQKS3QBuRuttRb0NwO3Z57cDeKqJvbxDq2zjndpmHE1+7Jq+/bmZNfwDwDpMvyP/awB/3YweEn1dAuDF7GNfs3sD8DimX9aVMP2K6AsAzgGwA8CB7LK3hXp7FMBLAPZgOlgrmtTbH2D6T8M9AHZnH+ua/dg5fTXkcdPpsiJB6Aw6kSAUdpEgFHaRIBR2kSAUdpEgFHaRIBR2kSD+D0iRXLx4HdClAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import datasets\n",
    "\n",
    "\n",
    "train_data = datasets.FashionMNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "\n",
    "valid_data = datasets.FashionMNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "                   \n",
    "train_idx = np.random.choice(train_data.train_data.shape[0], 54000, replace=False)\n",
    "train_data.data = train_data.data[train_idx, :]\n",
    "train_data.targets = train_data.targets[torch.from_numpy(train_idx).type(torch.LongTensor)]\n",
    "mask = np.ones(60000)\n",
    "mask[train_idx] = 0\n",
    "valid_data.data = valid_data.data[torch.from_numpy(np.argwhere(mask)), :].squeeze()\n",
    "valid_data.targets = valid_data.targets[torch.from_numpy(mask).type(torch.ByteTensor)]\n",
    "batch_size = 100\n",
    "test_batch_size = 100\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data,\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=test_batch_size, shuffle=True)\n",
    "plt.imshow(train_loader.dataset.train_data[1].numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "class FcNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 300)\n",
    "        self.fc2 = nn.Linear(300, 300)\n",
    "        self.fc3 = nn.Linear(300, 10)\n",
    "\n",
    "    def forward(self, image):\n",
    "        batch_size = image.size()[0]\n",
    "        x = image.view(batch_size, -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.log_softmax(self.fc3(x), dim=1)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)  # calls the forward function\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return model\n",
    "\n",
    "\n",
    "def valid(model, valid_loader):\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in valid_loader:\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        valid_loss += F.nll_loss(output, target, size_average=False).data # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    valid_loss /= len(valid_loader.dataset)\n",
    "    # print('\\n' + \"valid\" + ' set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    #     valid_loss, correct, len(valid_loader.dataset),\n",
    "    #     100. * correct / len(valid_loader.dataset)))\n",
    "    return valid_loss, 1. * correct / len(valid_loader.dataset)\n",
    "\n",
    "\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, size_average=False).data # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    # print('\\n' + \"test\" + ' set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    #     test_loss, correct, len(test_loader.dataset),\n",
    "    #     100. * correct / len(test_loader.dataset)))\n",
    "    return test_loss, 1. * correct / len(test_loader.dataset)\n",
    "\n",
    "def experiment(model, epochs=50, lr=0.001):\n",
    "    best_model = model\n",
    "    best_accuracy = 0\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model = train(model, train_loader, optimizer)\n",
    "        valid_loss, accuracy = valid(model, valid_loader)\n",
    "        losses.append(valid_loss)\n",
    "        accuracies.append(accuracy)\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model = model\n",
    "    return best_model, best_accuracy\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "\nvalid set: Average loss: 1.7044, Accuracy: 3701/6000 (62%)\n",
      "\n",
      "\nvalid set: Average loss: 1.2081, Accuracy: 3912/6000 (65%)\n",
      "\n",
      "\nvalid set: Average loss: 0.9711, Accuracy: 4033/6000 (67%)\n",
      "\n",
      "\nvalid set: Average loss: 0.8529, Accuracy: 4230/6000 (70%)\n",
      "\n",
      "\nvalid set: Average loss: 0.7817, Accuracy: 4403/6000 (73%)\n",
      "\n",
      "\nvalid set: Average loss: 0.7281, Accuracy: 4532/6000 (76%)\n",
      "\n",
      "\nvalid set: Average loss: 0.6870, Accuracy: 4641/6000 (77%)\n",
      "\n",
      "\nvalid set: Average loss: 0.6537, Accuracy: 4692/6000 (78%)\n",
      "\n",
      "\nvalid set: Average loss: 0.6243, Accuracy: 4775/6000 (80%)\n",
      "\n",
      "\nvalid set: Average loss: 0.6011, Accuracy: 4800/6000 (80%)\n",
      "\n",
      "\nvalid set: Average loss: 0.5811, Accuracy: 4823/6000 (80%)\n",
      "\n",
      "\nvalid set: Average loss: 0.5657, Accuracy: 4840/6000 (81%)\n",
      "\n",
      "\nvalid set: Average loss: 0.5507, Accuracy: 4876/6000 (81%)\n",
      "\n",
      "\nvalid set: Average loss: 0.5392, Accuracy: 4875/6000 (81%)\n",
      "\n",
      "\nvalid set: Average loss: 0.5287, Accuracy: 4905/6000 (82%)\n",
      "\n",
      "\nvalid set: Average loss: 0.5205, Accuracy: 4910/6000 (82%)\n",
      "\n",
      "\nvalid set: Average loss: 0.5146, Accuracy: 4911/6000 (82%)\n",
      "\n",
      "\nvalid set: Average loss: 0.5057, Accuracy: 4946/6000 (82%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4997, Accuracy: 4958/6000 (83%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4926, Accuracy: 4983/6000 (83%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4869, Accuracy: 4985/6000 (83%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4830, Accuracy: 5008/6000 (83%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4791, Accuracy: 4995/6000 (83%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4727, Accuracy: 5018/6000 (84%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4692, Accuracy: 5028/6000 (84%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4649, Accuracy: 5034/6000 (84%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4612, Accuracy: 5039/6000 (84%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4572, Accuracy: 5046/6000 (84%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4544, Accuracy: 5052/6000 (84%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4506, Accuracy: 5058/6000 (84%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4481, Accuracy: 5066/6000 (84%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4456, Accuracy: 5075/6000 (85%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4437, Accuracy: 5062/6000 (84%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4418, Accuracy: 5067/6000 (84%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4390, Accuracy: 5082/6000 (85%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4365, Accuracy: 5081/6000 (85%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4332, Accuracy: 5092/6000 (85%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4311, Accuracy: 5094/6000 (85%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4289, Accuracy: 5093/6000 (85%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4278, Accuracy: 5108/6000 (85%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4254, Accuracy: 5104/6000 (85%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4225, Accuracy: 5113/6000 (85%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4232, Accuracy: 5117/6000 (85%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4213, Accuracy: 5121/6000 (85%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4209, Accuracy: 5119/6000 (85%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4166, Accuracy: 5131/6000 (86%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4136, Accuracy: 5144/6000 (86%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4123, Accuracy: 5145/6000 (86%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4118, Accuracy: 5149/6000 (86%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4090, Accuracy: 5162/6000 (86%)\n",
      "\n",
      "\ntest set: Average loss: 0.4423, Accuracy: 8425/10000 (84%)\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "losses = []\n",
    "accuracies = []\n",
    "best_model = None\n",
    "best_accuracy = 0\n",
    "\n",
    "for model in [FcNetwork()]:  # add your models in the list\n",
    "    model, accuracy = experiment(model)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = model\n",
    "\n",
    "test(best_model, test_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}