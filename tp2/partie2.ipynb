{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "C:\\w\\1\\s\\tmp_conda_3.7_100118\\conda\\conda-bld\\pytorch_1579082551706\\work\\aten\\src\\ATen/native/IndexingUtils.h:20: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead.\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x23500ef5d48>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 41
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from tensorflow import keras\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# fashion_mnist = keras.datasets.fashion_mnist\n",
    "# \n",
    "# # load dataset\n",
    "# fashion_mnist = keras.datasets.fashion_mnist\n",
    "# (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "# K = len(np.unique(train_labels))\n",
    "# \n",
    "# X_train = np.reshape(train_images, (train_images.shape[0], train_images.shape[1]*train_images.shape[2]))\n",
    "# X_test = np.reshape(test_images, (test_images.shape[0], test_images.shape[1]*test_images.shape[2]))\n",
    "# \n",
    "# Y_train = np.zeros((train_labels.shape[0], K))\n",
    "# Y_train[np.arange(Y_train.shape[0]), train_labels] = 1\n",
    "# \n",
    "# Y_test = np.zeros((test_labels.shape[0], K))\n",
    "# Y_test[np.arange(Y_test.shape[0]), test_labels] = 1\n",
    "# \n",
    "# \n",
    "# X_test, X_validation, Y_test, Y_validation = train_test_split(X_test, Y_test, test_size=0.5, random_state=42)\n",
    "# \n",
    "# X_train = torch.tensor(X_train.T)\n",
    "# X_validation = torch.tensor(X_validation.T)\n",
    "# X_test = torch.tensor(X_test.T)\n",
    "# \n",
    "# Y_train = torch.tensor(Y_train.T)\n",
    "# Y_validation = torch.tensor(Y_validation.T)\n",
    "# Y_test = torch.tensor(Y_test.T)\n",
    "\n",
    "train_data = datasets.FashionMNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "\n",
    "valid_data = datasets.FashionMNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "                   \n",
    "train_idx = np.random.choice(train_data.train_data.shape[0], 54000, replace=False)\n",
    "train_data.data = train_data.data[train_idx, :]\n",
    "train_data.targets = train_data.targets[torch.from_numpy(train_idx).type(torch.LongTensor)]\n",
    "mask = np.ones(60000)\n",
    "mask[train_idx] = 0\n",
    "valid_data.data = valid_data.data[torch.from_numpy(np.argwhere(mask)), :].squeeze()\n",
    "valid_data.targets = valid_data.targets[torch.from_numpy(mask).type(torch.ByteTensor)]\n",
    "batch_size = 100\n",
    "test_batch_size = 100\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data,\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=test_batch_size, shuffle=True)\n",
    "plt.imshow(train_loader.dataset.train_data[1].numpy())\n",
    "\n",
    "# "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "class FcNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 300)\n",
    "        self.fc2 = nn.Linear(300, 300)\n",
    "        self.fc3 = nn.Linear(300, 10)\n",
    "\n",
    "    def forward(self, image):\n",
    "        batch_size = image.size()[0]\n",
    "        x = image.view(batch_size, -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.log_softmax(self.fc3(x), dim=1)\n",
    "        return x\n",
    "# \n",
    "# "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # data, target = Variable(data, volatile=True).cuda(), Variable(target).cuda() # if you have access to a gpu\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)  # calls the forward function\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return model\n",
    "\n",
    "\n",
    "def valid(model, valid_loader):\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in valid_loader:\n",
    "        # data, target = Variable(data, volatile=True).cuda(), Variable(target).cuda() # if you have access to a gpu\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        valid_loss += F.nll_loss(output, target, size_average=False).data # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    valid_loss /= len(valid_loader.dataset)\n",
    "    print('\\n' + \"valid\" + ' set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        valid_loss, correct, len(valid_loader.dataset),\n",
    "        100. * correct / len(valid_loader.dataset)))\n",
    "    return 1. * correct / len(valid_loader.dataset)\n",
    "\n",
    "\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        # data, target = Variable(data, volatile=True).cuda(), Variable(target).cuda() # if you have access to a gpu\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, size_average=False).data # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\n' + \"test\" + ' set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "def experiment(model, epochs=50, lr=0.001):\n",
    "    best_model = model\n",
    "    best_precision = 0\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model = train(model, train_loader, optimizer)\n",
    "        precision = valid(model, valid_loader)\n",
    "\n",
    "        if precision > best_precision:\n",
    "            best_precision = precision\n",
    "            best_model = model\n",
    "    return best_model, best_precision"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:39: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "\nvalid set: Average loss: 1.7622, Accuracy: 3700/6000 (62%)\n",
      "\n",
      "\nvalid set: Average loss: 1.2126, Accuracy: 3848/6000 (64%)\n",
      "\n",
      "\nvalid set: Average loss: 0.9705, Accuracy: 4049/6000 (67%)\n",
      "\n",
      "\nvalid set: Average loss: 0.8567, Accuracy: 4215/6000 (70%)\n",
      "\n",
      "\nvalid set: Average loss: 0.7886, Accuracy: 4319/6000 (72%)\n",
      "\n",
      "\nvalid set: Average loss: 0.7382, Accuracy: 4451/6000 (74%)\n",
      "\n",
      "\nvalid set: Average loss: 0.6996, Accuracy: 4561/6000 (76%)\n",
      "\n",
      "\nvalid set: Average loss: 0.6659, Accuracy: 4661/6000 (78%)\n",
      "\n",
      "\nvalid set: Average loss: 0.6380, Accuracy: 4702/6000 (78%)\n",
      "\n",
      "\nvalid set: Average loss: 0.6135, Accuracy: 4734/6000 (79%)\n",
      "\n",
      "\nvalid set: Average loss: 0.5951, Accuracy: 4764/6000 (79%)\n",
      "\n",
      "\nvalid set: Average loss: 0.5761, Accuracy: 4792/6000 (80%)\n",
      "\n",
      "\nvalid set: Average loss: 0.5613, Accuracy: 4836/6000 (81%)\n",
      "\n",
      "\nvalid set: Average loss: 0.5480, Accuracy: 4850/6000 (81%)\n",
      "\n",
      "\nvalid set: Average loss: 0.5365, Accuracy: 4870/6000 (81%)\n",
      "\n",
      "\nvalid set: Average loss: 0.5278, Accuracy: 4890/6000 (82%)\n",
      "\n",
      "\nvalid set: Average loss: 0.5189, Accuracy: 4898/6000 (82%)\n",
      "\n",
      "\nvalid set: Average loss: 0.5125, Accuracy: 4906/6000 (82%)\n",
      "\n",
      "\nvalid set: Average loss: 0.5045, Accuracy: 4931/6000 (82%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4981, Accuracy: 4948/6000 (82%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4932, Accuracy: 4967/6000 (83%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4883, Accuracy: 4968/6000 (83%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4820, Accuracy: 4980/6000 (83%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4777, Accuracy: 4984/6000 (83%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4743, Accuracy: 4989/6000 (83%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4696, Accuracy: 5003/6000 (83%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4670, Accuracy: 5012/6000 (84%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4623, Accuracy: 5015/6000 (84%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4597, Accuracy: 5022/6000 (84%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4562, Accuracy: 5028/6000 (84%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4530, Accuracy: 5039/6000 (84%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4505, Accuracy: 5039/6000 (84%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4476, Accuracy: 5048/6000 (84%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4443, Accuracy: 5057/6000 (84%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4419, Accuracy: 5050/6000 (84%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4411, Accuracy: 5059/6000 (84%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4372, Accuracy: 5061/6000 (84%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4381, Accuracy: 5060/6000 (84%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4328, Accuracy: 5066/6000 (84%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4325, Accuracy: 5070/6000 (84%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4315, Accuracy: 5068/6000 (84%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4267, Accuracy: 5076/6000 (85%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4255, Accuracy: 5070/6000 (84%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4239, Accuracy: 5077/6000 (85%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4221, Accuracy: 5101/6000 (85%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4201, Accuracy: 5094/6000 (85%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4177, Accuracy: 5094/6000 (85%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4171, Accuracy: 5103/6000 (85%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4151, Accuracy: 5101/6000 (85%)\n",
      "\n",
      "\nvalid set: Average loss: 0.4135, Accuracy: 5110/6000 (85%)\n",
      "\n",
      "\ntest set: Average loss: 0.4457, Accuracy: 8387/10000 (84%)\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "best_model = None\n",
    "best_precision = 0\n",
    "for model in [FcNetwork()]:  # add your models in the list\n",
    "    # model.cuda()  # if you have access to a gpu\n",
    "    model, precision = experiment(model)\n",
    "    if precision > best_precision:\n",
    "        best_precision = precision\n",
    "        best_model = model\n",
    "\n",
    "test(best_model, test_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}